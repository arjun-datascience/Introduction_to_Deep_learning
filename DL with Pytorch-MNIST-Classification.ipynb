{"cells":[{"metadata":{"colab":{},"colab_type":"code","id":"_17_ZnVDhCd0","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch import nn,optim\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd","execution_count":70,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"colab_type":"code","id":"lb2lrOr7hbdx","outputId":"92158888-fb2a-491e-8462-0698f118e14e","trusted":true},"cell_type":"code","source":"'''\nSTEP 1: LOADING DATASET\n'''\n\ntransform=transforms.Compose([transforms.ToTensor(),\n                             transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])])\ntrainset=datasets.MNIST('~/.pytorch/MNIST_data/',train=True,transform=transform,download=True)\ntestset=datasets.MNIST('~/.pytorch/MNIST_data/',train=False,transform=transform,download=True)\n\ntrainloader=torch.utils.data.DataLoader(trainset,batch_size=98,shuffle=True,num_workers=0)\n#will explain later\ntestloader=torch.utils.data.DataLoader(testset,batch_size=98,shuffle=True,num_workers=0)\n","execution_count":71,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"fD_LJ06Mh0re","trusted":true},"cell_type":"code","source":"class Network(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(784, 90)\n        self.fc2 = nn.Linear(90, 30)\n        self.fc3 = nn.Linear(30, 10)\n\n        # Dropout module with 0.2 drop probability\n        self.dropout = nn.Dropout(p=0.2)\n\n    def forward(self, x):\n        # make sure input tensor is flattened\n        x = x.view(x.shape[0], -1)\n\n        # Now with dropout\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.dropout(F.relu(self.fc2(x)))\n\n        # output so no dropout here\n        x = F.log_softmax(self.fc3(x), dim=1)\n\n        return x\n        \nmodel=Network()\n#optimizer=optim.Adam(model.parameters(),lr=0.001,momentum = 0.9)\noptimizer = optim.SGD(model.parameters(), lr=0.008, momentum=0.9, weight_decay=3.0e-4, nesterov = True)\ncriterion=nn.NLLLoss()","execution_count":72,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":102},"colab_type":"code","id":"OY0PFehch0ye","outputId":"14b32fc1-32e2-4d66-da92-379c436b9699","trusted":true},"cell_type":"code","source":"## Train\n\nepochs=10\ntrain_losses,test_losses=[],[]\nfor e in range(epochs):\n    running_loss=0\n    for images,labels in trainloader:\n        optimizer.zero_grad()\n        log_ps=model(images)\n        loss=criterion(log_ps,labels)\n        loss.backward()\n        optimizer.step()\n        running_loss+=loss.item()\n        \n    else:\n        test_loss=0\n        accuracy=0\n        \n        with torch.no_grad():\n            model.eval()\n            for images,labels in testloader:\n                log_ps=model(images)\n                test_loss+=criterion(log_ps,labels)\n                ps=torch.exp(log_ps)\n                top_p,top_class=ps.topk(1,dim=1)\n                equals=top_class==labels.view(*top_class.shape)\n                accuracy+=torch.mean(equals.type(torch.FloatTensor))\n        model.train()\n        train_losses.append(running_loss/len(trainloader))\n        test_losses.append(test_loss/len(testloader))\n\n        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\npytorch_total_params = sum(p.numel() for p in model.parameters())\nprint(\"Total no. of parameters : \",pytorch_total_params )        \n        ","execution_count":73,"outputs":[{"output_type":"stream","text":"Epoch: 1/10..  Training Loss: 0.772..  Test Loss: 0.306..  Test Accuracy: 0.909\nEpoch: 2/10..  Training Loss: 0.366..  Test Loss: 0.228..  Test Accuracy: 0.930\nEpoch: 3/10..  Training Loss: 0.294..  Test Loss: 0.180..  Test Accuracy: 0.949\nEpoch: 4/10..  Training Loss: 0.256..  Test Loss: 0.153..  Test Accuracy: 0.954\nEpoch: 5/10..  Training Loss: 0.233..  Test Loss: 0.147..  Test Accuracy: 0.954\nEpoch: 6/10..  Training Loss: 0.215..  Test Loss: 0.130..  Test Accuracy: 0.960\nEpoch: 7/10..  Training Loss: 0.197..  Test Loss: 0.135..  Test Accuracy: 0.958\nEpoch: 8/10..  Training Loss: 0.191..  Test Loss: 0.120..  Test Accuracy: 0.963\nEpoch: 9/10..  Training Loss: 0.178..  Test Loss: 0.112..  Test Accuracy: 0.967\nEpoch: 10/10..  Training Loss: 0.170..  Test Loss: 0.109..  Test Accuracy: 0.968\nTotal no. of parameters :  73690\n","name":"stdout"}]}],"metadata":{"colab":{"collapsed_sections":[],"name":"MNIST_assignment.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}